========================================
SETUP PIPELINE FLAGGING DATASET DIPLOY
========================================

PERSYARATAN:
- Conda/Miniconda/Anaconda (akan otomatis install Python 3.12.11)
- Akses internet untuk API Gemini dan Qdrant
- File dataset diploy yang sudah dipecah per 500 baris

========================================
LANGKAH 1: INSTALL CONDA (Jika Belum Ada)
========================================

1. Download Miniconda (versi lightweight Conda):
   # Untuk macOS (Intel):
   curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-x86_64.sh
   bash Miniconda3-latest-MacOSX-x86_64.sh
   
   # Untuk macOS (Apple Silicon/M1/M2):
   curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-arm64.sh
   bash Miniconda3-latest-MacOSX-arm64.sh
   
   # Untuk Linux:
   curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
   bash Miniconda3-latest-Linux-x86_64.sh
   
   # Untuk Windows:
   # Download dari: https://docs.conda.io/en/latest/miniconda.html
   # Jalankan installer dan ikuti wizard

2. Restart terminal setelah instalasi selesai

3. Verifikasi instalasi:
   conda --version

========================================
LANGKAH 2: SETUP CONDA ENVIRONMENT
========================================

1. Buka terminal dan navigasi ke folder project:
   cd "/Users/irz/Downloads/Data Diploy Koreksi API/Pipeline Flagging"

2. Buat conda environment dengan Python 3.12.11 dan install dependencies sekaligus:
   conda create -n diploy_flagging python=3.12.11 pandas openpyxl numpy -y

3. Aktivasi conda environment:
   conda activate diploy_flagging

4. Install dependencies tambahan via pip:
   pip install -r requirements.txt

========================================
LANGKAH 3: PERSIAPAN DATA
========================================

1. Pastikan struktur folder sudah ada:
   Pipeline Flagging/
   ├── Data Diploy Not Flagged/    # Folder input (file yang belum di-flag)
   └── Data Diploy Flagged/         # Folder output (file hasil flagging)

2. Jika belum ada, buat folder output:
   mkdir -p "Data Diploy Flagged"

3. Pastikan file input sudah ada di folder "Data Diploy Not Flagged"
   Format nama: diploy_unflagged_1-500.xlsx, diploy_unflagged_501-1000.xlsx, dst.

========================================
LANGKAH 4: KONFIGURASI
========================================

1. Buka file flagging_dataset_diploy_gemini.ipynb

2. Periksa dan sesuaikan konfigurasi di bagian KONFIGURASI:
   
   a. API_KEY: 
      - Pastikan API key Gemini masih valid
      - Dapatkan dari: https://makersuite.google.com/app/apikey
   
   b. CONCURRENCY:
      - Default: 3 (3 request parallel)
      - Bisa dinaikkan jika koneksi stabil (maks 5-10)
      - Bisa diturunkan jika sering timeout
   
   c. INPUT_FILE dan OUTPUT_FILE:
      - Ganti XXX-XXX dengan range file yang ingin diproses
      - Contoh: diploy_unflagged_1-500.xlsx
      
   d. QDRANT_URL dan QDRANT_API_KEY:
      - Pastikan akses ke Qdrant masih valid
      - Collection: OKUPASI_SFT_AITF_V2

========================================
LANGKAH 5: MENJALANKAN PIPELINE
========================================

1. Buka Jupyter Notebook atau VS Code dengan ekstensi Jupyter

2. Pilih kernel Python dari conda environment yang sudah dibuat:
   - Klik "Select Kernel" di pojok kanan atas
   - Pilih: Python 3.12.11 ('diploy_flagging')

3. Edit INPUT_FILE dan OUTPUT_FILE untuk file yang ingin diproses:
   INPUT_FILE  = f"{DRIVE_DATASET_DIR}/Data Diploy Not Flagged/diploy_unflagged_1-500.xlsx"
   OUTPUT_FILE = f"{DRIVE_DATASET_DIR}/Data Diploy Flagged/diploy_flagged_gemini_1-500.xlsx"

4. Jalankan cell utama (cell kedua)

5. Tunggu hingga proses selesai
   - Progress bar akan menunjukkan status
   - Output akan disimpan otomatis ke folder "Data Diploy Flagged"

========================================
LANGKAH 6: MONITORING & TROUBLESHOOTING
========================================

1. Monitoring:
   - Perhatikan output console untuk error/timeout
   - Cek progress bar untuk estimasi waktu
   - File output akan tersimpan otomatis

2. Jika ada timeout:
   - Turunkan CONCURRENCY (misalnya dari 3 ke 2)
   - Periksa koneksi internet
   - Tunggu beberapa saat dan retry

3. Jika ada error JSON parsing:
   - Biasanya response LLM tidak valid
   - File akan ter-flag dengan Area_Fungsi dan Level_Okupasi kosong
   - Bisa diproses ulang secara manual

4. Jika file output kosong (0 baris):
   - Periksa path INPUT_FILE sudah benar
   - Pastikan file input ada dan tidak kosong
   - Jalankan cell debug untuk verifikasi

========================================
LANGKAH 7: VERIFIKASI HASIL
========================================

1. Cek file output di folder "Data Diploy Flagged"

2. Buka file Excel dan verifikasi:
   - Kolom Area_Fungsi terisi
   - Kolom Level_Okupasi terisi
   - Jumlah baris sama dengan input

3. Statistik hasil:
   - Hitung jumlah per Area_Fungsi
   - Hitung distribusi Level
   - Identifikasi "Okupasi Non TIK"

========================================
TIPS & BEST PRACTICES
========================================

1. Selalu backup data sebelum processing
2. Proses per batch (500 baris) untuk stabilitas
3. Monitor penggunaan API quota Gemini
4. Simpan log error untuk troubleshooting
5. Verifikasi hasil secara berkala
6. Jangan interrupt proses di tengah jalan

========================================
ESTIMASI WAKTU
========================================

Untuk 500 baris dengan CONCURRENCY=3:
- Waktu per baris: ~3-5 detik
- Total waktu: ~25-40 menit per file
- Total 13594 baris (~28 file): ~12-18 jam

========================================
CONTACT & SUPPORT
========================================

Jika ada masalah:
1. Cek dokumentasi Gemini API
2. Cek status Qdrant Cloud
3. Periksa requirements.txt sudah terinstall semua
4. Restart kernel jika ada memory leak

========================================
